---
layout: post
title: CKA 공부 34일차
subtitle: ''
categories: devops
tags: k8s
comments: false
---

## Cluster Networking

- k8s 클러스터는 마스터, 노드를 가지며 각각의 노드는 하나의 인터페이스를 가지며 이 인터페이스는 하나의 IP 주소를 갖는다.

- 호스트들은 유니크한 이름을 갖는데, 잘 알다시피 맥어드레스다.

- 마스터노드는 기본적으로 API 서버로의 6443 포트를 허용한다.

- 각 노드의 kubelet은 10250 포트로 통신할 수 있다. 물론 당연히 마스터노드에서 kubelet은 대표가 될 수 없다. (kube-api server로만 통신 가능)

- kube-scheduler의 경우 10251 포트를 오픈한다.

- controller-manager는 10252이다.

- 워커노드의 서비스들은 30000-32767 포트를 오픈한다.

- ETCD 서버는 2379 포트를 오픈한다.

- 만약 마스터노드가 여러 개라면 추가적인 ETCD 2380 포트를 열고 서로 통신할 수 있게 한다.

## Pod Networking

- 각각의 파드들은 노드 내에 Bridge와 연결되며 IP 주소를 할당받는다.

- 각 노드간의 파드들은 서로 통신할 수 있는 구조여야하는데, 이를 위해서는 일일이 파드가 생성될 때 마다 가상 케이블 만들고, 연결하고, Namespace에 IP 주소 주소 연결하고, 셋팅하는 이런 작업들을 스크립트로 만들어둬서 매 파드가 생성될 때 마다 이 작업을 해야한다.

- 이를 위한 더 나은 솔루션은 노드들을 모두 연결하는 라우터를 둬서 특정 IP CIDR로 들어오는 요청에 대해서는 특정 노드로 전달시켜줘버리는 것이다.

- 가령, 192.16.1.11이라는 노드 1번을 게이트웨이에 명시해두고, 네트워크에 10.244.1.0/24를 주면 해당 IP 범위로 들어오는 요청은 노드 1번으로 보내서 내부 브릿지에서 판다하여 특정 파드로 전달하는 것이 가능할 것이다.

- 이러한 방법은 10.244.0.0/16이라는 노드 간의 방대한 네트워크를 만드는 것과 동일하다.

- 그러면 매 분마다 수 천개읲 파드들이 생성될텐데 어떻게 이 스크립트를 자동화할 수 있을까?

- 여기서 CNI가 다시 등장한다.

- CNI는 일종의 중개자 역할을 담당하는데, CNI는 쿠버네티스에게 `파드가 만들어지자 마자 뭘 할지를 명시해서 알려줘`라는 내용을 스크립트로 줘야한다.

- CNI식으로 스크립트를 짜보면 다음과 같다.

### net-script.sh

```bash
# ADD
ip -n <namespace> link set ...

# Del
ip link del ...
```

- 스크립트는 준비됐다.

- kubelet은 각 노드에서 생성될 때 마다 컨테이너 생성을 담당한다.

- kubelet은 먼저 커맨드라인 옵션으로 던져주는 CNI 설정 값을 확인한다.

- 그리고 나서 CNI bin 디렉토리를 정의한다. 여기에는 우리의 스크립트가 정의되어있고 스크립트를 실행한다.

- 그러고나서 `./net-script.sh add <container> <namespace>`를 확인한다.

## CNI in k8s

- CNI 인터페이스를 구현하는 plugin을 사용하여 k8s 네트워크를 설정할 수 있다.

- CNI plugin은 컨테이너를 생성하는 책임을 가진 쿠버네티스 컴포넌트에게 불려진다.

- CNI pliguin은 클러스태 내에 있는 각 노드의 kubelet 서비스에 설정되어진다.

- `kubelet.service` 파일을 확인해보면 CNI 네트워크 플러그인 설정 옵션을 확인할 수 있다.

## CNI weave

- 다른 노드에 있는 파드간의 통신을 위해서 라우팅 테이블로는 100개가 넘는 노드의 네트워크와 게이트웨이를 일일이 정의하기란 쉽지 않다.

- 여기서 필요한 것이 바로 CNI plugin이다.

- CNI plugin 중 하나인 `weave`에 대해서 알아보자.

- `weave`는 각각의 노드에 `agent`를 배치시킨다. 이 `agent`들은 서로 연결되어있고, 특정 노드에서 나가는 패킷을 `agent`가 가로챈다.

- 그리고 이 패킷을 한번 포장한 다음, 전달하고 전달받은 측에서는 이 패키지를 풀어서 원본을 파드에게 전달한다.

- 이게 가능한 이유는 `agent`끼리 연결되어있기 때문이고 이를 위한 CNI plugin이 이러한 네트워크를 담당해주기 때문이다.

## Weave 배포는 어떻게?

- `weave`는 클러스터 내에서 명령을 통해 서비스나 데몬으로 각 노드에 배포될 수 있다.

- 만약 클러스터에 마스터노드와 워커노드가 배포되어있고, control plan component가 배포되어있다면 `weave`를 배포할 수 있다.

- `kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\n')`

- 위 명령어가 수행되면 `weave peers`라고 하는 데몬셋이 배포되어진다.

- 위 명령어를 수행한 이후 `kube-system` 네임스페이스로 파드를 조회해보면 `weave-net-{id}`로 데몬셋 파드들이 각 노드마다 배포된 것을 볼 수 있다.